{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I had three datasets that we collected and gathered and saved them by putting them in three dataframes\n",
    "we needed to generate our authenication and our API keys using tweeter developer account.\n",
    "there was a file provided by udacity called ( twitter-archive-enhanced.csv) this file was read and saved using pandas in a dataframe called df\n",
    "\n",
    "second dataframe that we needed twitter api tokens and API keys, for it I used a library called *tweepy* that deals with twitter api then I used it to get authorization, then I made a for loop to create a tweet_json.txt file that was looping and getting the tweets ids then we saved it in a dataframe called df2\n",
    "\n",
    "for the third and the last dataset we had a url provided by udacity that contain the data \n",
    "we used the library called *requests* then we created a file called image predicitions that contains the content of the response by querying our url, then we saved it in dataframe called df3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment for the data \n",
    "\n",
    "for assessment of the data we had two ways to make this assessment, they are visually and programmingly we will make the assessment for the three dataframes\n",
    "\n",
    "### For the first dataframe\n",
    "> visual assessment\n",
    "\n",
    "this dataframe called df and it contains the csv file twitter-archive-enhanced.csv, I first made a visual assessment for the whole dataframe using the line ( df.head() ) then It is clear that this line is insufficient to give you a whole intuition and a proof about the dataframe, then I used another line to give more indication about the dataframe this line gives me a random sample from the dataframe not in a order so this can reveal if the data has nulls or a wrong values this line that I am talking about and I wrote for the visual assessment of the first dataframe is ( df.sample() )\n",
    "\n",
    "> programming assessment\n",
    "\n",
    "\n",
    "I used ( df.info() ) to get a full data about the dataframe and I found it is 17 columns with 2356 entries and I also found some info interesting that some columns have many null values, these columns are ( in_reply_to_status_id , in_reply_to_user_id , retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)\n",
    "\n",
    "then I used ( df.describe() ) to give me info about the minimum and maximum values for each column, this line strikes me with an obvious uncleaned issue, it is that I found that the maximum value in the rating denominator is 170 and the rest of the values is clearly 10, this is an obvious issue of an outlier that may be caused when someone entered this value or number\n",
    "then I tried to investigate the columns of the ( floofer, puppo, pupper , doggo) to see how many have values and how have a none as a value I found that the majority of each of column of them have a none as a value, so that a thing to work on it and we must also pay attention that they are four columns for one variable, I investigated these columns using the method ( value_counts) of pandas\n",
    "\n",
    "also I saw that the timestamp column that its type need to be changed as it is a object string type, we need to change datetime\n",
    "\n",
    "the source column contain many url as http internet format that need to be cleaned so that we can get the source only\n",
    "\n",
    "\n",
    "I had to look also on some columns to see their values closely and that could be achieved using ( unique() ) method of pandas \n",
    "and I applied this method on the following columns (retweeted_status_timestamp,retweeted_status_user_id, in_reply_to_status_id\n",
    "then I thought it will be useful and interesting to look on the names of the dog in the data we have and surprisingly I found an important issue, we have a strange and incorrect name like ( a ) who would name a dog after a single letter and we had 55 names for dogs like that , so that was an issue to solve later\n",
    "I investigated if there is a duplicated tweet ids usind ( . duplicated() ) method but checking reveals that there were no duplicates \n",
    "\n",
    "Finally I saw that the rating numerator is always 10 so no need to have this column, this is an issue of tidness \n",
    "\n",
    "\n",
    "### For the second dataframe \n",
    "> visual assessment \n",
    "   \n",
    "this dataframe called df2 and it contains data we got from the url provided by udacity using requests, I first made a visual assessment for the whole dataframe using the line ( df2.head() ) then It is clear that this line is insufficient to give you a whole intuition and a proof about the dataframe, then I used another line to give more indication about the dataframe this line gives me a random sample from the dataframe not in a order so this can reveal if the data has nulls or a wrong values this line that I am talking about and I wrote for the visual assessment of the second dataframe is ( df2.sample() )\n",
    "and I found that some algorithms gives a predicition of something not a dog\n",
    "> programming assessment\n",
    "\n",
    "when I made df2.describe() to if there are any odds that will make an issue I didn't found anything.\n",
    "then I made a check on whether any of columns has true value or all are false  if the three columns are all false, this won't be a useful information as it will not be an image of a dog so it is made using ( .query ), we wrote the line df2.query(\"p3_dog==True | p1_dog==True | p2_dog==True\")\n",
    "\n",
    "we noticed that jpg_url column, the jpg_url isn't the same url as the expanded url in df1, one opens the photo of the dog and thee other opens the photo of the dog giving the status and the tweet in twitter\n",
    "\n",
    "### For the third dataframe \n",
    "\n",
    "> visual assessment \n",
    "\n",
    "\n",
    "\n",
    "this dataframe called df3 and it contains the data we queried from the json file that we collected used twitter API, I used df3.head()  ,  and df3.sample() to give us intuition , I found that many columns are redundant and don't any useful info so that I may should remove some of them\n",
    "\n",
    "\n",
    "\n",
    "> programming assessment\n",
    "\n",
    "\n",
    "\n",
    "we used  ( df3.info() ) we got information about dataframe it is 2331 entries and it is total 32 columns, but I found that many of them contain too many null values that will be noisy and disturbant and would add no value or info these colums like (contributors, coordinates, geo , in_reply_to_screen_name,in_reply_to_status_id, in_reply_to_status_id_str ,in_reply_to_user_id, in_reply_to_user_id_str , place, quoted_status quoted_status_id,quoted_status_id_str ,quoted_status_permalink, retweeted_status)\n",
    "\n",
    "I also tried to check if there are any tweet_ids duplicated\n",
    "I noticed that the source column need to be cleaned and dealt with , in the same manner we did with the former dataframe\n",
    "A problem to notice that the ids of tweets here are under the column of a name id so we need to change it to tweet_id column to keep the consistency among our data\n",
    "another thing you notice that the column name of time here under a name of created_at and we need to change it to a timestamp so keep the consistency of the names\n",
    "the type of the column of the created_at is an object ( string) so we need to change it to datetime\n",
    "so many cleaning and removing for columns is needed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of the dataframes\n",
    "\n",
    "\n",
    "### For the first dataframe\n",
    "\n",
    "- Changing the (a) name of the dog to None as it is the most suitable logical value that the dog could have instead of having a letter as a name\n",
    "I had to replace the name of the dog that is said to be *a* to be none instead as no logic to have a dog name to be *a*\n",
    "I did it using (.replace) method\n",
    "I checked after replacng by querying if there is a still a name with a \n",
    "- changing the timestamp to type datetime and make sure that no date beyond 1 august 2017\n",
    " it was requested to have no tweets beyond august 2017 so that something to take care of, also i needed to change timestamp column from object type to datetime type\n",
    " first I sliced the data inside that column taking the first 10 characters using .str.slice method of pandas\n",
    " then I converted this column into datetime using pd.to_datetime function of pandas choosing the suitable format then to filter the dates to avoid having date beyod august 2017 , I used df.query\n",
    " the test is done using df.info() to see the new type of the column \n",
    " \n",
    "- Combining the one variable that is in 4 columns into one column called type as they are the same variable ( I mean the puppo, floofer , etc)\n",
    "then they are the last columns in my dataframe I used lambda function and the join function to join these values in the columns into a new created column called type then I will replace the values of these column to hae the type that we want \n",
    "we knew the values that are in this dataframe using *df['Type'].value_counts()* then we used replace to replace the unique values we got with the suitable values \n",
    "some values while cleaning this data required from me to look at thetext associated with this tweet so that i can write the correct type \n",
    "after that I dropped the 4 columns and i left the type column only\n",
    "\n",
    "- Dropping the unimportant columns inreply to status id , in reply to user id , retweeted status timestamp , rating denominator \n",
    "- Checking the retweeted tweets in our dataframe and remove them\n",
    " I wrote this line *df[df['retweeted_status_id'].isna()==False]* to see and investigate the retweets and I coded and made a query to remove the retweets columns writing this *df = df[df['retweeted_status_id'].isna()==True]*\n",
    " - dropping the retweeted_status_id and the retweeted_status_user id\n",
    " by using the .drop method in pandas\n",
    " - Cleaning the source column to clearly have an info about the real source of the data meaning extract the real source not the whole url\n",
    " made a use of .find method of string to find a place of a word that repeats then used the index to get the source only\n",
    "- we need to drop the old source column so we have only one source column containing the useful info\n",
    "\n",
    "\n",
    "\n",
    "### For the second dataframe\n",
    "- cleaning the first issue as we need the data where p1 or p2 or p3 is true indicating that the photo is a dog\n",
    "writing this line would do it *df2 = df2.query(\"p3_dog==True | p1_dog==True | p2_dog==True\")*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### for the third dataframe\n",
    "\n",
    "-  drop the unimportant columns ( contributors,coordinates,user,place,geo,truncated,entites,extended_entities)\n",
    "- change the source column as we did in df1 so that we extract the important ssource only then remove the original source column from our dataframe\n",
    "- Changing the name of Id column to tweet_id to keep the consistency among our data\n",
    "- Dropping the following colums after checking that retweeted tweets are false in all of them in_reply_to_screen_name, in_reply_to_status_id, in_reply_to_status_id_str possibly_sensitive, possibly_sensitive_appealable,display_text_range\n",
    "\n",
    "- checking the values to know if there is a true in the column in (is_quote_status) so we drop them if true\n",
    " writing this line helped us to achieve it *df3[df3['is_quote_status']==True]*\n",
    "- we must drop also where the column of ( retweeted_status isn't Nan)\n",
    " writing this line *df3 = df3[df3['retweeted_status'].isnull()==True]*\n",
    "- changing the type of (created at) column to be datetime instead of object\n",
    "first by slicing the time to get the last characters and slicingthe first character putting each in a column then concatenate them in a new column then remove the old and used columns to get our target then after that use pd.datetime to convert the last column\n",
    "- Changing the order of the columns so that it is suitable according to the useful information\n",
    "writing this line *df3 = df3.reindex(columns=['tweet_id','timestamp','favorite_count','retweet_count','Source','full_text'])*\n",
    "- we need to remove the full text column as it is in df already no need to be in df3\n",
    "\n",
    "## Saving and joining the dataframes\n",
    "\n",
    "\n",
    "### we need to join the suitable dataframes and then save them in a csv\n",
    "- df_tot= pd.merge(df,df3,how='inner')\n",
    "\n",
    "- re arrange the columns so the important ones comes first\n",
    "*df_tot.reindex(columns['tweet_id','timestamp','favorite_count','retweet_count','rating_numerator','name','Type','Source','text','expanded_urls']*\n",
    "\n",
    "- saving them by writing *df_tot.to_csv('Combined_data.csv')*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
